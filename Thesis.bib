% Encoding: UTF-8

@article {surp2015,
  author = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on
               ImageNet Classification},
  journal = {CoRR},
  volume = {abs / 1502.01852},
  year = {2015},
  url = {http://arxiv.org/abs/1502.01852},
  archivePrefix = {arXiv},
  eprint = {1502.01852},
  timestamp = {Wed, Apr 17 2019 17:23:45 +0200},
  biburl = {https://dblp.org/rec/journals/corr/HeZR015.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article {resnet,
  author = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title = {Deep Residual Learning for Image Recognition},
  journal = {CoRR},
  volume = {abs / 1512.03385},
  year = {2015},
  url = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint = {1512.03385},
  timestamp = {Wed, Apr 17 2019 17:23:45 +0200},
  biburl = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article {efficientnet,
  author = {Mingxing Tan and
               Quoc V. Le},
  title = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  journal = {CoRR},
  volume = {abs / 1905.11946},
  year = {2019},
  url = {http://arxiv.org/abs/1905.11946},
  archivePrefix = {arXiv},
  eprint = {1905.11946},
  timestamp = {Mon, 03 Jun 2019 13:42:33 +0200},
  biburl = {https://dblp.org/rec/journals/corr/abs-1905-11946.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{bmw, 
    title={BMW Group Selects NVIDIA to Redefine Factory Logistics: NVIDIA Blog}, 
    url={https://blogs.nvidia.com/blog/2020/05/14/bmw-nvidia-isaac-factory-logistics/}, 
    journal={The Official NVIDIA Blog}, 
    author={14, May and Csongor, Rob}, 
    year={2020}, 
    month={7}
}

@article{McCulloch_1943,
	doi = {10.1007/bf02478259},
	url = {https://doi.org/10.1007%2Fbf02478259},
	year = 1943,
	month = {12},
	publisher = {Springer Science and Business Media {LLC}},
	volume = {5},
	number = {4},
	pages = {115--133},
	author = {Warren S. McCulloch and Walter Pitts},
	title = {A logical calculus of the ideas immanent in nervous activity},
	journal = {The Bulletin of Mathematical Biophysics}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{DBLP:journals/corr/Schmidhuber14,
  author    = {J{\"{u}}rgen Schmidhuber},
  title     = {Deep Learning in Neural Networks: An Overview},
  journal   = {CoRR},
  volume    = {abs/1404.7828},
  year      = {2014},
  url       = {http://arxiv.org/abs/1404.7828},
  archivePrefix = {arXiv},
  eprint    = {1404.7828},
  timestamp = {Mon, 13 Aug 2018 16:47:28 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Schmidhuber14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{mic_definitions,
author = {Deng, Li and Yu, Dong},
title = {Deep Learning: Methods and Applications},
year = {2014},
issue_date = {June 2014},
publisher = {Now Publishers Inc.},
address = {Hanover, MA, USA},
volume = {7},
number = {3–4},
issn = {1932-8346},
url = {https://doi.org/10.1561/2000000039},
doi = {10.1561/2000000039},
abstract = {This monograph provides an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria in mind: (1) expertise or knowledge of the authors; (2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and (3) the application areas that have the potential to be impacted significantly by deep learning and that have been experiencing research growth, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning.},
journal = {Found. Trends Signal Process.},
month = jun,
pages = {197–387},
numpages = {191},
keywords = {Supervised learning, Hybrid deep networks, Computer vision, Language models, Unsupervised learning, Deep neural networks, Object recognition, Deep stacking networks, Autoencoders, Multi-task learning, Neural networks, Artificial intelligence, Deep learning, Multi-modal processing, Natural language processing, Machine learning}
}

@ARTICLE{DBN,
AUTHOR = {Hinton, G. E.},
TITLE   = {{D}eep belief networks},
YEAR    = {2009},
JOURNAL = {Scholarpedia},
VOLUME  = {4},
NUMBER  = {5},
PAGES   = {5947},
DOI     = {10.4249/scholarpedia.5947},
NOTE    = {revision \#91189}
}

@article{mnist,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}

@misc{nielsenneural,
  added-at = {2019-01-15T22:46:49.000+0100},
  author = {Nielsen, Michael A.},
  biburl = {https://www.bibsonomy.org/bibtex/274383acee84241145ff4ffede9658206/slicside},
  interhash = {04d527cadd39f888fc3babcad3343362},
  intrahash = {74383acee84241145ff4ffede9658206},
  keywords = {ba-2018-hahnrico},
  publisher = {Determination Press},
  timestamp = {2019-01-15T22:46:49.000+0100},
  title = {Neural Networks and Deep Learning},
  type = {misc},
  url = {http://neuralnetworksanddeeplearning.com/},
  year = 2018
}

@InProceedings{pmlr-v15-glorot11a, title = {Deep Sparse Rectifier Neural Networks}, author = {Xavier Glorot and Antoine Bordes and Yoshua Bengio}, pages = {315--323}, year = {2011}, editor = {Geoffrey Gordon and David Dunson and Miroslav Dudík}, volume = {15}, series = {Proceedings of Machine Learning Research}, address = {Fort Lauderdale, FL, USA}, month = {11--13 Apr}, publisher = {JMLR Workshop and Conference Proceedings}, pdf = {http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf}, url = {http://proceedings.mlr.press/v15/glorot11a.html}, abstract = {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised neural networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training. [pdf]} }

@Book{bileschi2020deep,
 author = {Bileschi, Stanley},
 title = {Deep Learning with JavaScript},
 publisher = {Manning Publications},
 year = {2020},
 address = {City},
 isbn = {9781617296178}
 }
 
 @misc{wei2019generative,
      title={Generative Image Translation for Data Augmentation in Colorectal Histopathology Images}, 
      author={Jerry Wei and Arief Suriawinata and Louis Vaickus and Bing Ren and Xiaoying Liu and Jason Wei and Saeed Hassanpour},
      year={2019},
      eprint={1910.05827},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
}

@INPROCEEDINGS{outperforming,
  author={Z. {Dai} and X. {Huang} and W. {Chen} and L. {He} and H. {Zhang}},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)}, 
  title={A Comparison of CNN-Based and Hand-Crafted Keypoint Descriptors}, 
  year={2019},
  volume={},
  number={},
  pages={2399-2404},
  doi={10.1109/ICRA.2019.8793701}}
  
@INPROCEEDINGS{sift,
  author={D. G. {Lowe}},
  booktitle={Proceedings of the Seventh IEEE International Conference on Computer Vision}, 
  title={Object recognition from local scale-invariant features}, 
  year={1999},
  volume={2},
  number={},
  pages={1150-1157 vol.2},
  doi={10.1109/ICCV.1999.790410}}
  
@article{surf,
title = "Speeded-Up Robust Features (SURF)",
journal = "Computer Vision and Image Understanding",
volume = "110",
number = "3",
pages = "346 - 359",
year = "2008",
note = "Similarity Matching in Computer Vision and Multimedia",
issn = "1077-3142",
doi = "https://doi.org/10.1016/j.cviu.2007.09.014",
url = "http://www.sciencedirect.com/science/article/pii/S1077314207001555",
author = "Herbert Bay and Andreas Ess and Tinne Tuytelaars and Luc {Van Gool}",
keywords = "Interest points, Local features, Feature description, Camera calibration, Object recognition",
abstract = "This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with SURF’s application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF’s usefulness in a broad range of topics in computer vision."
}

@INPROCEEDINGS{hog,
  author={N. {Dalal} and B. {Triggs}},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)}, 
  title={Histograms of oriented gradients for human detection}, 
  year={2005},
  volume={1},
  number={},
  pages={886-893 vol. 1},
  doi={10.1109/CVPR.2005.177}}
  
@article{svm,
  title={Support-vector networks},
  author={Cortes, Corinna and Vapnik, Vladimir},
  journal={Machine learning},
  volume={20},
  number={3},
  pages={273--297},
  year={1995},
  publisher={Springer}
}

@article{comparison_illustration,
title = "Deep learning for smart manufacturing: Methods and applications",
journal = "Journal of Manufacturing Systems",
volume = "48",
pages = "144 - 156",
year = "2018",
note = "Special Issue on Smart Manufacturing",
issn = "0278-6125",
doi = "https://doi.org/10.1016/j.jmsy.2018.01.003",
url = "http://www.sciencedirect.com/science/article/pii/S0278612518300037",
author = "Jinjiang Wang and Yulin Ma and Laibin Zhang and Robert X. Gao and Dazhong Wu",
keywords = "Smart manufacturing, Deep learning, Computational intelligence, Data analytics",
abstract = "Smart manufacturing refers to using advanced data analytics to complement physical science for improving system performance and decision making. With the widespread deployment of sensors and Internet of Things, there is an increasing need of handling big manufacturing data characterized by high volume, high velocity, and high variety. Deep learning provides advanced analytics tools for processing and analysing big manufacturing data. This paper presents a comprehensive survey of commonly used deep learning algorithms and discusses their applications toward making manufacturing “smart”. The evolvement of deep learning technologies and their advantages over traditional machine learning are firstly discussed. Subsequently, computational methods based on deep learning are presented specially aim to improve system performance in manufacturing. Several representative deep learning models are comparably discussed. Finally, emerging topics of research on deep learning are highlighted, and future trends and challenges associated with deep learning for smart manufacturing are summarized."
}

